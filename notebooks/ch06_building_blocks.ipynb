{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d3gycmVRcqp"
      },
      "source": [
        "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
      ],
      "id": "-d3gycmVRcqp"
    },
    {
      "cell_type": "markdown",
      "id": "ee061b9e",
      "metadata": {
        "id": "ee061b9e"
      },
      "source": [
        "# Deep Learning Basics with PyTorch\n",
        "\n",
        "**Dr. Yves J. Hilpisch with GPT-5**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2af24b5",
      "metadata": {
        "id": "c2af24b5"
      },
      "source": [
        "# Chapter 6 â€” Building Blocks of Neural Networks\n",
        "Colab-ready notebook covering neurons, activations, manual forward passes, and XOR decision boundaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5c9uEJfRcqr"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook provides a concise, hands-on walkthrough of Deep Learning Basics with PyTorch.\n",
        "Use it as a companion to the chapter: run each cell, read the short notes,\n",
        "and try small variations to build intuition.\n",
        "\n",
        "Tips:\n",
        "- Run cells top to bottom; restart kernel if state gets confusing.\n",
        "- Prefer small, fast experiments; iterate quickly and observe outputs.\n",
        "- Keep an eye on shapes, dtypes, and devices when using PyTorch.\n"
      ],
      "id": "G5c9uEJfRcqr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e877572b",
      "metadata": {
        "id": "e877572b"
      },
      "outputs": [],
      "source": [
        "  # !pip -q install torch numpy matplotlib scikit-learn\n",
        "import torch, numpy as np, matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8')  # plotting\n",
        "%config InlineBackend.figure_format = 'retina'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258aef74",
      "metadata": {
        "id": "258aef74"
      },
      "source": [
        "## Activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf37fd50",
      "metadata": {
        "id": "bf37fd50"
      },
      "outputs": [],
      "source": [
        "x = torch.linspace(-4, 4, steps = 9)\n",
        "torch.sigmoid(x), torch.tanh(x), torch.relu(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2867bab9",
      "metadata": {
        "id": "2867bab9"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-6, 6, 400)\n",
        "plt.figure(figsize = (5, 3))  # plotting\n",
        "plt.plot(x, 1/(1+np.exp(-x)), label = 'sigmoid')\n",
        "plt.plot(x, np.tanh(x), label = 'tanh')\n",
        "plt.plot(x, np.maximum(0, x), label = 'ReLU')\n",
        "plt.legend(frameon = False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ae866d",
      "metadata": {
        "id": "95ae866d"
      },
      "source": [
        "## Manual forward for a 2-layer MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9b0273",
      "metadata": {
        "id": "bd9b0273"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)  # reproducibility\n",
        "x = torch.randn(5, 2)\n",
        "W1 = torch.randn(2, 4)  # layer 1 weights\n",
        "b1 = torch.randn(4)  # layer 1 bias\n",
        "W2 = torch.randn(4, 1)  # layer 2 weights\n",
        "b2 = torch.randn(1)  # layer 2 bias\n",
        "h = torch.relu(x @ W1 + b1)  # hidden activations\n",
        "y = h @ W2 + b2  # targets/labels\n",
        "y.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f47720",
      "metadata": {
        "id": "57f47720"
      },
      "source": [
        "## XOR decision boundary: linear vs 2-layer MLP (quick demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1cea3d",
      "metadata": {
        "id": "fe1cea3d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# RNG setup and data generation\n",
        "rng = np.random.default_rng(0)\n",
        "X = rng.uniform(-1, 1, size=(600, 2))  # inputs\n",
        "y = ((X[:, 0] > 0) ^ (X[:, 1] > 0)).astype(int)  # XOR-like targets\n",
        "X = X + rng.normal(0, 0.15, size=X.shape)  # add noise\n",
        "\n",
        "# Baseline linear classifier\n",
        "lin = LogisticRegression().fit(X, y)\n",
        "\n",
        "# Two-layer MLP parameters\n",
        "W1 = torch.randn(2, 8, requires_grad=True)\n",
        "b1 = torch.zeros(8, requires_grad=True)\n",
        "W2 = torch.randn(8, 2, requires_grad=True)\n",
        "b2 = torch.zeros(2, requires_grad=True)\n",
        "\n",
        "# Light init scaling without tracking gradients\n",
        "with torch.no_grad():\n",
        "    W1.mul_(0.5)\n",
        "    W2.mul_(0.5)\n",
        "\n",
        "# Numpy -> Torch tensors\n",
        "X_t = torch.tensor(X, dtype=torch.float32)\n",
        "y_t = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Simple SGD loop\n",
        "for _ in range(1500):\n",
        "    h = torch.relu(X_t @ W1 + b1)  # hidden activations\n",
        "    logits = h @ W2 + b2\n",
        "    loss = torch.nn.functional.cross_entropy(logits, y_t)\n",
        "\n",
        "    # Zero grads, backprop, and parameter update\n",
        "    for p in (W1, b1, W2, b2):\n",
        "        if p.grad is not None:\n",
        "            p.grad.zero_()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for p in (W1, b1, W2, b2):\n",
        "            p -= 0.1 * p.grad\n",
        "\n",
        "# Plot decision regions after training\n",
        "xmin, xmax = X[:, 0].min() - 0.4, X[:, 0].max() + 0.4\n",
        "ymin, ymax = X[:, 1].min() - 0.4, X[:, 1].max() + 0.4\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(xmin, xmax, 200), np.linspace(ymin, ymax, 200)\n",
        ")\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "with torch.no_grad():\n",
        "    h = torch.relu(torch.tensor(grid, dtype=torch.float32) @ W1 + b1)\n",
        "    zz_mlp = (h @ W2 + b2).argmax(dim=1).numpy().reshape(xx.shape)\n",
        "    zz_lin = lin.predict(grid).reshape(xx.shape)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(8, 3), sharex=True, sharey=True)\n",
        "for a, zz, title in zip(ax, [zz_lin, zz_mlp], ['Linear', '2-layer MLP']):\n",
        "    a.contourf(xx, yy, zz, levels=[-0.5, 0.5, 1.5], cmap='coolwarm', alpha=0.25)\n",
        "    a.scatter(X[y == 0, 0], X[y == 0, 1], s=8)\n",
        "    a.scatter(X[y == 1, 0], X[y == 1, 1], s=8)\n",
        "    a.set_title(title)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKPI1jmwRcqt"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Implement a custom activation and compare its curve to ReLU/GELU.\n",
        "2. Assemble a tiny two-layer network and print intermediate shapes.\n"
      ],
      "id": "fKPI1jmwRcqt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcdj1EZfRcqt"
      },
      "source": [
        "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
      ],
      "id": "xcdj1EZfRcqt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}