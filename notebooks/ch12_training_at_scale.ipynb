{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f13480c",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d00e3",
   "metadata": {},
   "source": [
    "# Deep Learning Basics with PyTorch\n",
    "\n",
    "**Dr. Yves J. Hilpisch with GPT-5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3dfb2d",
   "metadata": {},
   "source": [
    "# Chapter 12 â€” Training at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b17c8",
   "metadata": {},
   "source": [
    "## Throughput quick check (toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ae1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.randn(256, 64, device = device)\n",
    "w = torch.randn(64, 64, device = device)\n",
    "torch.cuda.synchronize() if device.type=='cuda' else None\n",
    "t0 = time.time()\n",
    "for _ in range(500):\n",
    "    y = x @ w  # targets/labels\n",
    "    torch.cuda.synchronize() if device.type=='cuda' else None\n",
    "    elapsed = time.time() - t0\n",
    "    elapsed\n",
    "    # 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63398125",
   "metadata": {},
   "source": [
    "## AMP training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f90836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = nn.Linear(128, 10).to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "use_amp = (device.type == 'cuda')\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "\n",
    "x = torch.randn(32, 128, device=device)\n",
    "y = torch.randint(0, 10, (32,), device=device)\n",
    "\n",
    "opt.zero_grad(set_to_none=True)\n",
    "if use_amp:\n",
    "    # Mixed precision region on CUDA\n",
    "    with torch.amp.autocast('cuda', enabled=True):\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        else:\n",
    "            # Fallback: full precision on CPU/Metal\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad(set_to_none=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793c58b",
   "metadata": {},
   "source": [
    "## Gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = nn.Linear(128, 10).to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr = 1e-2)  # optimizer setup / step\n",
    "accum = 4\n",
    "opt.zero_grad(set_to_none = True)\n",
    "for step in range(8):\n",
    "    x = torch.randn(16, 128, device = device)\n",
    "    y = torch.randint(0, 10, (16, ), device = device)  # targets/labels\n",
    "    loss = F.cross_entropy(model(x), y) / accum  # training objective\n",
    "    loss.backward()\n",
    "    if (step+1) % accum == 0:\n",
    "        opt.step()\n",
    "        opt.zero_grad(set_to_none = True)\n",
    "        # None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3b8f4",
   "metadata": {},
   "source": [
    "## Checkpoint save/load (toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d02433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "state = {'model': {'w': torch.randn(2)}, 'epoch': 3}\n",
    "torch.save(state, 'checkpoint.pt')\n",
    "ckpt = torch.load('checkpoint.pt', map_location = device)\n",
    "ckpt['epoch'], isinstance(ckpt['model'], dict)\n",
    "# (3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a0646",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}