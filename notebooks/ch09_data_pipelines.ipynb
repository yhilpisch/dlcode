{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c0087",
   "metadata": {},
   "source": [
    "# Deep Learning Basics with PyTorch\n",
    "\n",
    "**Dr. Yves J. Hilpisch with GPT-5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1240c3",
   "metadata": {},
   "source": [
    "# Chapter 9 â€” Working with Data in PyTorch\n",
    "Datasets, DataLoaders, transforms, and batching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n\n",
    "This notebook provides a concise, hands-on walkthrough of Deep Learning Basics with PyTorch.\n",
    "Use it as a companion to the chapter: run each cell, read the short notes,\n",
    "and try small variations to build intuition.\n\n",
    "Tips:\n",
    "- Run cells top to bottom; restart kernel if state gets confusing.\n",
    "- Prefer small, fast experiments; iterate quickly and observe outputs.\n",
    "- Keep an eye on shapes, dtypes, and devices when using PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # !pip -q install torch numpy matplotlib scikit-learn\n",
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587d362",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader (moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "X, y = make_moons(n_samples=600, noise=0.25, random_state=0)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "X_tr = torch.tensor(X_tr, dtype=torch.float32)\n",
    "X_te = torch.tensor(X_te, dtype=torch.float32)\n",
    "y_tr = torch.tensor(y_tr, dtype=torch.long)\n",
    "y_te = torch.tensor(y_te, dtype=torch.long)\n",
    "\n",
    "  # Wrap tensors as datasets and loaders\n",
    "train_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_te, y_te), batch_size=256)\n",
    "\n",
    "class TinyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = TinyMLP()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for Xb, yb in train_loader:\n",
    "        logits = model(Xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accuracy = (model(X_te).argmax(1) == y_te).float().mean().item()\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ae2b5",
   "metadata": {},
   "source": [
    "## Transform: standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        def __call__(self, x):\n",
    "            return (x - self.mean) / (self.std + 1e-8)\n",
    "\n",
    "            mu, sigma = X_tr.mean(0), X_tr.std(0)\n",
    "            std = Standardize(mu, sigma)\n",
    "            X_tr_s, X_te_s = std(X_tr), std(X_te)\n",
    "\n",
    "            train_loader = DataLoader(TensorDataset(X_tr_s, y_tr), batch_size = 64,  # wrap tensors as a dataset\n",
    "                shuffle = True)\n",
    "            test_loader = DataLoader(TensorDataset(X_te_s, y_te), batch_size = 256)  # wrap tensors as a dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6504e5b",
   "metadata": {},
   "source": [
    "## Custom collate (variable length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySeq(Dataset):\n",
    "    def __init__(self, rng, n = 20):\n",
    "        self.x = [torch.tensor(rng.integers(1, 10, size = rng.integers(3,\n",
    "            8))) for _ in range(n)]\n",
    "        self.y = [int(xi.sum() % 2) for xi in self.x]\n",
    "        def __len__(self):\n",
    "            return len(self.x)\n",
    "            def __getitem__(self, i):\n",
    "                return self.x[i].float(), self.y[i]\n",
    "\n",
    "                def pad_collate(batch):\n",
    "                    xs, ys = zip(*batch)\n",
    "                    L = max(x.size(0) for x in xs)\n",
    "                    Xp = torch.zeros(len(xs), L)\n",
    "                    for i, x in enumerate(xs):\n",
    "                        Xp[i, :x.size(0)] = x\n",
    "                        return Xp, torch.tensor(ys, dtype = torch.long)\n",
    "\n",
    "                        rng = np.random.default_rng(0)  # RNG setup\n",
    "                        seq_loader = DataLoader(ToySeq(rng), batch_size = 4,  # create data loader\n",
    "                            collate_fn = pad_collate)\n",
    "                        xb, yb = next(iter(seq_loader))\n",
    "                        xb.shape, yb.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n\n",
    "1. Write a tiny custom Dataset; use a DataLoader and inspect batching/padding.\n",
    "2. Measure throughput for two DataLoader settings (num_workers, pin_memory).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
