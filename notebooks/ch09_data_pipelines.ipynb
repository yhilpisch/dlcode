{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f3bbe1",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c0087",
   "metadata": {},
   "source": [
    "# Deep Learning Basics with PyTorch\n",
    "\n",
    "**Dr. Yves J. Hilpisch with GPT-5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1240c3",
   "metadata": {},
   "source": [
    "# Chapter 9 â€” Working with Data in PyTorch\n",
    "Datasets, DataLoaders, transforms, and batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install torch numpy matplotlib scikit-learn\n",
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587d362",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader (moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "X, y = make_moons(n_samples=600, noise=0.25, random_state=0)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "X_tr = torch.tensor(X_tr, dtype=torch.float32)\n",
    "X_te = torch.tensor(X_te, dtype=torch.float32)\n",
    "y_tr = torch.tensor(y_tr, dtype=torch.long)\n",
    "y_te = torch.tensor(y_te, dtype=torch.long)\n",
    "\n",
    "# Wrap tensors as datasets and loaders\n",
    "train_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(X_te, y_te), batch_size=256)\n",
    "\n",
    "class TinyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 2))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = TinyMLP()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Quick training loop\n",
    "for _ in range(10):\n",
    "    model.train()\n",
    "    for Xb, yb in train_loader:\n",
    "        loss = loss_fn(model(Xb), yb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "model.eval()\n",
    "float(((model(X_te).argmax(1) == y_te).float().mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ae2b5",
   "metadata": {},
   "source": [
    "## Transform: standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-8)\n",
    "\n",
    "mu, sigma = X_tr.mean(0), X_tr.std(0)\n",
    "std = Standardize(mu, sigma)\n",
    "X_tr_s, X_te_s = std(X_tr), std(X_te)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_tr_s, y_tr), batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(X_te_s, y_te), batch_size=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6504e5b",
   "metadata": {},
   "source": [
    "## Custom collate (variable length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySeq(Dataset):\n",
    "    def __init__(self, rng, n=20):\n",
    "        self.x = [torch.tensor(rng.integers(1, 10, size=rng.integers(3, 8))) for _ in range(n)]\n",
    "        self.y = [int(xi.sum() % 2) for xi in self.x]\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i].float(), self.y[i]\n",
    "\n",
    "def pad_collate(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    L = max(x.size(0) for x in xs)\n",
    "    Xp = torch.zeros(len(xs), L)\n",
    "    for i, x in enumerate(xs):\n",
    "        Xp[i, :x.size(0)] = x\n",
    "    return Xp, torch.tensor(ys, dtype=torch.long)\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "seq_loader = DataLoader(ToySeq(rng), batch_size=4, collate_fn=pad_collate)\n",
    "xb, yb = next(iter(seq_loader))\n",
    "xb.shape, yb.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3717d1a",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}