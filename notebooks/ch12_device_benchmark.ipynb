{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2cf41db",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca7b9e",
   "metadata": {},
   "source": [
    "# Deep Learning Basics with PyTorch\n",
    "\n",
    "**Dr. Yves J. Hilpisch with GPT-5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67175c5e",
   "metadata": {},
   "source": [
    "# Chapter 12 â€” Training at Scale\n",
    "Cross-device benchmark: CPU vs MPS vs CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01322fe6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Benchmark CPU, Apple's MPS, and NVIDIA CUDA by timing a small training loop and inference pass.\n",
    "The goal is to compare relative throughput rather than optimize model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aaab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install torch torchvision matplotlib  # install dependencies if running in a fresh env\n",
    "import time  # timing utilities\n",
    "from dataclasses import dataclass  # structured configuration object\n",
    "from typing import Iterable  # type hints for helpers\n",
    "\n",
    "import torch  # core tensor library\n",
    "from torch import nn  # neural network layers\n",
    "from torch.utils.data import DataLoader, TensorDataset  # lightweight dataset utilities\n",
    "\n",
    "from IPython import get_ipython  # runtime configuration tweaks\n",
    "\n",
    "get_ipython().run_line_magic(\"config\", \"InlineBackend.figure_format = 'retina'\")\n",
    "torch.manual_seed(0)  # ensure reproducible random data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abb71f",
   "metadata": {},
   "source": [
    "## Benchmark configuration\n",
    "\n",
    "Configure dataset size, model width, and batch size for the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfe649",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BenchmarkConfig:\n",
    "    num_samples: int = 50_000  # synthetic dataset size\n",
    "    num_features: int = 300  # feature dimensionality\n",
    "    num_classes: int = 10  # number of classes\n",
    "    hidden_dim: int = 512  # hidden width for MLP\n",
    "    batch_size: int = 512  # data loader batch size\n",
    "    epochs: int = 3  # training epochs per device\n",
    "\n",
    "CONFIG = BenchmarkConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e740234",
   "metadata": {},
   "source": [
    "## Synthetic dataset helper\n",
    "\n",
    "Return a reproducible toy classification dataset used by the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaa5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(cfg: BenchmarkConfig) -> TensorDataset:\n",
    "    \"\"\"Return a synthetic classification dataset.\"\"\"\n",
    "    features = torch.randn(cfg.num_samples, cfg.num_features)  # random features\n",
    "    labels = torch.randint(0, cfg.num_classes, (cfg.num_samples,))  # random class labels\n",
    "    return TensorDataset(features, labels)  # wrap in TensorDataset for PyTorch loaders\n",
    "\n",
    "DATASET = make_dataset(CONFIG)  # materialize once for entire notebook run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc88e06",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "Use a small MLP so training focuses on throughput rather than complex architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d04494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(cfg: BenchmarkConfig) -> nn.Module:\n",
    "    \"\"\"Create a simple feed-forward classifier.\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(cfg.num_features, cfg.hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(cfg.hidden_dim, cfg.num_classes),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9da139",
   "metadata": {},
   "source": [
    "## Device enumeration\n",
    "\n",
    "Detect CPU, Apple's Metal (mps), and CUDA devices available on this machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_devices() -> list[str]:\n",
    "    devices = ['cpu']  # CPU always present\n",
    "    if torch.backends.mps.is_available():\n",
    "        devices.append('mps')\n",
    "    if torch.cuda.is_available():\n",
    "        devices.append('cuda')\n",
    "    return devices\n",
    "\n",
    "AVAILABLE = available_devices()\n",
    "print(\"devices detected:\", AVAILABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e78ee",
   "metadata": {},
   "source": [
    "## Training benchmark helper\n",
    "\n",
    "Time a brief training loop on the given device using the shared configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_training(device: str, cfg: BenchmarkConfig) -> float:\n",
    "    model = make_model(cfg).to(device)  # move model to target device\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)  # simple optimizer\n",
    "    loader = DataLoader(DATASET, batch_size=cfg.batch_size, shuffle=True)  # iterate dataset\n",
    "    criterion = nn.CrossEntropyLoss()  # classification loss\n",
    "\n",
    "    start = time.perf_counter()  # start timer\n",
    "    for epoch in range(cfg.epochs):  # iterate epochs\n",
    "        for xb, yb in loader:  # iterate mini-batches\n",
    "            xb = xb.to(device)  # move features\n",
    "            yb = yb.to(device)  # move labels\n",
    "            optimizer.zero_grad(set_to_none=True)  # clear gradients\n",
    "            logits = model(xb)  # forward pass\n",
    "            loss = criterion(logits, yb)  # compute loss\n",
    "            loss.backward()  # backpropagate\n",
    "            optimizer.step()  # update weights\n",
    "    if device == 'cuda':  # synchronize CUDA kernels before stopping timer\n",
    "        torch.cuda.synchronize()\n",
    "    return time.perf_counter() - start  # elapsed seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff748444",
   "metadata": {},
   "source": [
    "## Inference benchmark helper\n",
    "\n",
    "Measure average inference latency per batch on each device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(device: str, cfg: BenchmarkConfig) -> float:\n",
    "    model = make_model(cfg).to(device)\n",
    "    model.eval()\n",
    "    batch = torch.randn(cfg.batch_size, cfg.num_features, device=device)  # synthetic batch\n",
    "    with torch.no_grad():\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(200):\n",
    "            _ = model(batch)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return elapsed / 200  # average seconds per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241447d",
   "metadata": {},
   "source": [
    "## Run benchmarks\n",
    "\n",
    "Execute training and inference benchmarks across available devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be562ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for device in AVAILABLE:\n",
    "    train_time = benchmark_training(device, CONFIG)\n",
    "    infer_time = benchmark_inference(device, CONFIG)\n",
    "    results.append((device, train_time, infer_time))\n",
    "\n",
    "for device, train_time, infer_time in results:\n",
    "    print(f\"{device:>4} | train {train_time:.2f}s | infer {infer_time * 1e3:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b1aff",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Adjust `BenchmarkConfig` (e.g., larger `num_features`) and observe throughput differences.\n",
    "- Switch the optimizer to Adam or add an extra hidden layer to test impact on device scaling.\n",
    "- Increase `epochs` and compare how startup overhead differs across devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b330599",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
