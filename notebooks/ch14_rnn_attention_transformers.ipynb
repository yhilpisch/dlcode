{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07c77ad",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b46690",
   "metadata": {},
   "source": [
    "# Deep Learning Basics with PyTorch\n",
    "\n",
    "**Dr. Yves J. Hilpisch with GPT-5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc1df2",
   "metadata": {},
   "source": [
    "# Chapter 14 â€” Recurrent and Attention-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f4200",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook provides a concise, hands-on walkthrough of Deep Learning Basics with PyTorch.\n",
    "Use it as a companion to the chapter: run each cell, read the short notes,\n",
    "and try small variations to build intuition.\n",
    "\n",
    "Tips:\n",
    "- Run cells top to bottom; restart kernel if state gets confusing.\n",
    "- Prefer small, fast experiments; iterate quickly and observe outputs.\n",
    "- Keep an eye on shapes, dtypes, and devices when using PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976ab2f",
   "metadata": {},
   "source": [
    "## Scaled dot-product attention (masked vs unmasked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"Apply scaled dot-product attention and return outputs plus weights.\"\"\"\n",
    "    scores = (Q @ K.transpose(-2, -1)) / math.sqrt(Q.size(-1))\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(~mask, float('-inf'))\n",
    "    weights = torch.softmax(scores, dim=-1)\n",
    "    return weights @ V, weights\n",
    "\n",
    "\n",
    "T, D = 4, 3\n",
    "Q = torch.randn(T, D)\n",
    "K = torch.randn(T, D)\n",
    "V = torch.randn(T, D)\n",
    "\n",
    "causal_mask = torch.tril(torch.ones(T, T, dtype=torch.bool))\n",
    "_, masked_weights = scaled_dot_product_attention(Q, K, V, causal_mask)\n",
    "_, unmasked_weights = scaled_dot_product_attention(Q, K, V)\n",
    "\n",
    "masked_weights.shape, unmasked_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73e43b",
   "metadata": {},
   "source": [
    "## Multi-head attention shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d879a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHES, T, D_MODEL, HEADS = 2, 5, 8, 2\n",
    "D_HEAD = D_MODEL // HEADS\n",
    "x = torch.randn(BATCHES, T, D_MODEL)\n",
    "\n",
    "Wq = torch.randn(D_MODEL, D_MODEL)\n",
    "Wk = torch.randn(D_MODEL, D_MODEL)\n",
    "Wv = torch.randn(D_MODEL, D_MODEL)\n",
    "\n",
    "Q = x @ Wq\n",
    "K = x @ Wk\n",
    "V = x @ Wv\n",
    "\n",
    "Q = Q.view(BATCHES, T, HEADS, D_HEAD).transpose(1, 2)\n",
    "K = K.view(BATCHES, T, HEADS, D_HEAD).transpose(1, 2)\n",
    "V = V.view(BATCHES, T, HEADS, D_HEAD).transpose(1, 2)\n",
    "\n",
    "scores = (Q @ K.transpose(-2, -1)) / (D_HEAD ** 0.5)\n",
    "scores.shape  # torch.Size([2, 2, 5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d33c8",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Change the number of heads or d_model in a tiny transformer; compare training curves.\n",
    "2. Visualize attention for a few prompts and discuss patterns you see.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c0633",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
